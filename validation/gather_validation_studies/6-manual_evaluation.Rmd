---
title: "6: Manual evaluation of files and preparation for validation"
author: David Wilkins
date: Generated `r lubridate::now()`
output:
  html_document:
    toc: true
    theme: readable
---

```{r global_options, include = FALSE}
library(knitr)
opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r message = FALSE}
library(tidyverse)
library(printr)
library(readxl)
library(fs)
library(rentrez)
library(XML)
library(memoise)
library(cli)
library(rscopus)
library(easyPubMed)
```

At this step I'm going to go through each file manually and assess its suitability for inclusion in the validation set. If it appears suitable, I'll prepare the source list and study description for validation.

First, let's load the shortlist of files that have passed evaluation to this point.

```{r}
files <- readRDS("./evaluations.rds") %>%
  as_tibble() %>%
  filter(include)
```

For reviews that are included in the validation set, the source list and study description will be stored in `validation_data`.

```{r}
if (! dir_exists ("validation_data")) dir_create("validation_data")
```

# Social Norms and Suicidality

The first three files come from the project 'Social Norms and Suicidality - Scoping Review' (\url{https://osf.io/btpzc/}). A draft manuscript for the scoping review is available [here](https://osf.io/xbhuq); as far as I can tell it hasn't been published anywhere yet.

My short name for this review will be `suicide_norms`.

## Title and abstract screening results

There are three files related to this project: `Nov 20 Stage 3 Review of full text - completed Feb21.xlsx`, `Nov20 Stage 2 Removal of duplicates and screenings.xlsx`, and `June 2022 Screenings Extraction TOP UP.xlsx`.

`Nov20 Stage 2 Removal of duplicates and screenings.xlsx` contains a sheet 'Title Abstract screenings' which includes columns for title, abstract, and 'Screened IN/OUT - reason?'. I note that a lot of the abstracts seem to be missing but this is not an insurmountable problem. 

I'll load and tidy this sheet.

```{r}
suicide_norms_tas <- read_excel("osf_files/Nov20 Stage 2 Removal of duplicates and screenings.xlsx", sheet = "Title Abstract screenings", range = "A1:G12411") %>%
  select(title = Title, abstract = Abstract, decision_reason = `Screened IN/OUT - reason?`)
```

In the same file, there is also a sheet called 'Further Abstract Screens'. It's unclear how this differed from 'Title Abstract screenings', so I'll load this sheet and compare the two.

```{r}
suicide_norms_fas <- read_excel("osf_files/Nov20 Stage 2 Removal of duplicates and screenings.xlsx", sheet = "Further Abstract Screens", range = "A1:H1706") %>%
  select(title = Title, abstract = Abstract, decision_reason = `Abstract Screen in/out`)
```

How many sources in each sheet?

```{r}
nrow(suicide_norms_tas)
nrow(suicide_norms_fas)
```

So, does 'Further Abstract Screens' represent a secondary stage of screening sources that passed 'Title Abstract screenings'? To figure this out, I'll first try to parse the screening results in 'Title Abstract screenings'.

```{r}
suicide_norms_tas <- suicide_norms_tas %>%
  mutate(decision = str_extract(decision_reason, "^(IN|OUT|UNSURE)"))

count(suicide_norms_tas, decision)
```

The parsing appears to be successful. So, does 'Further Abstract Screens' only contain the sources that were not excluded at 'Title Abstract screenings'?

```{r}
passed_tas_titles <- suicide_norms_tas %>%
  filter(decision %in% c("IN", "UNSURE")) %>%
  pull(title)

sum(! suicide_norms_fas$title %in% passed_tas_titles)
```

It seems that this is the case for all but one source. Let's take a close look at this source.

```{r}
suicide_norms_fas %>%
  filter(! title %in% passed_tas_titles) %>%
  pull(title)
```

After manually inspecting both sheets in MS Excel, it seems like this is due to a difference in the title; it appears as 'Suicidality correlates in Mexican Americans.' in 'Title Abstract screenings', with the other details being identical.

A likely explanation for these two sheets is that 'Further Abstract Screens' represents cases where extra effort was made to retrieve abstracts that were not available at the stage of 'Title Abstract screenings'. This will also be relevant to the use of this review for validation, as of course the abstract is required for validation. Let's compare the availablity of abstracts between the two sheets to confirm this.

```{r}
suicide_norms_tas %>%
  count(is.na(abstract))

suicide_norms_fas %>%
  count(is.na(abstract))
```

Surprisingly, there are still a large number of missing abstracts in 'Further Abstract Screens', including some for which the reason for exclusion was given as 'abstract not relevant'. There are also quite a few for which the abstract is given as '(No abstract)' or '(Can't paste abstract here)'. Nevertheless, it seems like this is the most appropriate list to use as the gold standard, since these are the sources for which a human actually looked at the title and abstract. I'll filter the list to remove missing abstracts including '(No abstract)' and similar.

```{r}
suicide_norms_fas <- suicide_norms_fas %>%
  filter(! is.na(abstract))

suicide_norms_fas %>%
  count(is.na(title))

suicide_norms_fas %>%
  count(is.na(decision_reason))

suicide_norms_fas %>%
  count(abstract) %>%
  filter(n > 1) %>%
  arrange(desc(n))

suicide_norms_fas <- suicide_norms_fas %>%
  filter(! abstract %in% c("(No abstract)", "(Can't paste abstract here)", "No abstract", "(Book review)", "(LETTER)", "(Editorial)", "(no abstract?)", "No abstract?", "(Not English / no abstract)", "DUPLICATE"))

suicide_norms_fas %>%
  count(abstract) %>%
  filter(n > 1) %>%
  arrange(desc(n))
```

There still seem to be eight cases where the abstract is replicated, including one where it appears three times. Are the titles replicated for these examples too?

```{r}
suicide_norms_fas %>%
  group_by(abstract) %>%
  mutate(abstract_n = n()) %>%
  ungroup() %>%
  filter(abstract_n > 1) %>%
  arrange(abstract)
```

Yes, it appears that the majority of these are accidental replicates, perhaps between between preprints and final publications. Given that there are some differences between the titles, I think the best way to handle this is to include them in the validation set, as they do represent places where the human reviewer could potentially have chosen differently (although in practice it seems they made the same decision for all these cases).

As the final preparation step for this sources list, I'll normalise the human decisions.

```{r}
suicide_norms_fas <- suicide_norms_fas %>%
  mutate(decision = str_extract(decision_reason, "^(IN|OUT)"))

suicide_norms_fas %>%
  count(decision)

suicide_norms_fas <- suicide_norms_fas %>%
  mutate(human_includes = decision == "IN") %>%
  select(-decision_reason, -decision)
```

There are two other MS Excel files associated with this project that were shortlisted. `Nov 20 Stage 3 Review of full text - completed Feb21.xlsx`, as the name suggests, seems to be the results of full text screening, so this can be ignored. 

`June 2022 Screenings Extraction TOP UP.xlsx` appears to contain the results of a second round of searches performed about a year and a half after the initial search. It's unclear to what extent this overlaps with the result of the initial search, so I'll load and tidy the sheet 'Title Abs Screening' to compare.

```{r}
suicide_norms_topup <- read_excel("osf_files/June 2022 Screenings Extraction TOP UP.xlsx", sheet = "Title Abs Screening", range = "A3:G1076") %>%
  select(title = Title, abstract = Abstract, decision_reason = "Title/Abstract Screening")

sum(suicide_norms_fas$title %in% suicide_norms_topup$title)
sum(suicide_norms_topup$title %in% suicide_norms_fas$title)
```

It appears there is little overlap; this would fit with the following from the Methods of the draft manuscript:

> Initial literature searches were restricted to articles published until the end of October 2020, with a top-up search conducted in June 2022 for articles published between November 2020 and May 2022. 

So, I'll tidy the list of top up sources, removing missing abstracts, and add them to the pool.

```{r}
suicide_norms_topup <- suicide_norms_topup %>%
  filter(! is.na(abstract))

suicide_norms_topup %>%
  group_by(abstract) %>%
  mutate(abstract_n = n()) %>%
  ungroup() %>%
  filter(abstract_n > 1)

suicide_norms_topup <- suicide_norms_topup %>%
  mutate(decision = str_extract(decision_reason, "^(IN|OUT)"))

suicide_norms_topup %>%
  count(decision)

suicide_norms_topup <- suicide_norms_topup %>%
  mutate(human_includes = decision == "IN") %>%
  select(-decision_reason, -decision)

suicide_norms_sources <- bind_rows(suicide_norms_fas, suicide_norms_topup)
saveRDS(suicide_norms_sources, "validation_data/suicide_norms_sources.rds")
```

## Study description

I'll draw the study description and inclusion criteria from the draft manuscript.

```{r}
suicide_norms_study_description <- 
"STUDY DESCRIPTION:

Given that suicide can be conceptualised as a form of health-behaviour based on the formation of intentions, and considering the role of perceived social norms in determining other health-related behaviours and behavioural intentions, there remains a lack of reviews of the extent of the published research literature on the role of perceived social norms in suicidality and self-harm related outcomes. The present systematic scoping review aimed to identify the forms of perceived social norms which have been associated with self-harm and suicidality (i.e., suicidal thoughts, feelings, attempts, and help-seeking) and the role of perceived social norms in these outcomes.

DEFINITIONS:

Social norms are a key influence on personal behaviours and are broadly defined as 'rules and standards that are understood by members of a group, and that guide and/or constrain social behaviour without the force of law'. Social norms influence behavioural intention formation, the engagement in various behaviours, and are featured in a number of key models of health-related behaviour, most notably the Theory of Planned Behavior.

INCLUSION CRITERIA:

- Investigated the role of perceived social norms in the individual experience of suicide-related thoughts, feelings and/or behaviours including self-harm or non-suicidal self-injury (e.g. as an outcome variable in quantitative studies or part of a research question or an identified theme for qualitative studies)
- Original empirical research
- Published in the English language

EXCLUSION CRITERIA:

- Review articles or commentaries
- Studies on suicide attacks (e.g., suicide bombings, suicide terrorism), murder-suicides, or assisted suicide (i.e., euthanasia)
"
saveRDS(suicide_norms_study_description, "validation_data/suicide_norms_study_description.rds")
```

# The bibliometric approach in scientific publications on thanatology

A single file `REFERENCES FOR SCRINING.xlsx` comes from the project 'The bibliometric approach in scientific publications on thanatology: A scoping review.' (\url{https://osf.io/ukfpq/}). 

After reviewing the project on OSF, searching on Google Scholar, and reviewing the publication history of the first author, I was unable to identify any published or draft manuscript associated with this project. So, unfortunately it cannot be used for validation.

# Investigating the psychology of shipping among fans

Two files, `1st Screening.xlsx` and `RawData.xlsx`, come from the project 'Investigating The Psychology of Shipping Among Fans: A Scoping Review' (\url{https://osf.io/yjs43/}). There is a [protocol](https://osf.io/tcd6g) associated with the project on OSF.

## Title and abstract screening results

Both spreadsheets contain a list of sources including titles and abstracts. The sources in '1st screening' appear to be a subset of those in 'RawData'. There is some colour coding of cells in both spreadsheets but no column that explicitly contains title and abstract screening results. It is likely that '1st screening' represents sources that passed initial title and abstract screening, but this is not clear enough to justify the use of this project for validation.

# Open Science Practices in Gambling Research Publications 

One file, `OS_scoping_eligible_references_from_database_search.xlsx`, comes from the project 'Open Science Practices in Gambling Research Publications: A Scoping Review' (\url{https://osf.io/xw7gf/}). There is a [preprint manuscript](https://osf.io/a82vn/) available associated with this project.

## Title and abstract screening results

On review of the file `OS_scoping_eligible_references_from_database_search.xlsx` as well as associated files on the project's OSF page, it is not clear if this file represents sources that have passed title and abstract screening or full text screening. It therefore cannot be used for validation.

# Health care for people with disabilities in the Unified Health System in Brazil

One file, `Análise das categorias - última etapa.xlsx`, comes from the project 'Scoping Review - Health care for people with disabilities in the Unified Health System in Brazil' (\url{https://osf.io/8mghk/}). The project has a [document giving PRISMA reporting items](https://osf.io/3qukm) which contains a brief summary of the study objectives and inclusion/exclusion criteria.

On further review of the spreadsheet it is clearly a full coding table, not the results of title and abstract screening, and so cannot be used for validation.

# Social relationships and their associations with affective symptoms of women with breast cancer

One file, `review_113315_included_csv_20220615125644.csv`, comes from the project 'Social relationships and their associations with affective symptoms of women with breast cancer' (\url{https://osf.io/f3me9/}). This scoping review has been published as:pr

Yang, Y. et al. Social relationships and their associations with affective symptoms of women with breast cancer: A scoping review. PLoS ONE 17, e0272649 (2022).

On review of the file, it appears to list sources that passed title and abstract review only. So, unfortunately it cannot be used for validation.

# Documentation, process and implementation of advance care planning in the pediatric population

One file, `S2_Irrelevant records excluded_2023May26.csv`, comes from the project 'Documentation, process and implementation of advance care planning in the pediatric population: A scoping review' (\url{https://osf.io/e6k8c/}). There is a [preprint scoping review protocol](https://osf.io/6ksv5/) associated with the project.

## Title and abstract screening results

The file `S2_Irrelevant records excluded_2023May26.csv`, as the name would suggest, includes only a list of the sources that failed title and abstract screening. However, the project data folder includes two other files, `S3_Full-text excluded_2023 May 26.csv` and `S5_Data Extraction Results_2023May18.csv`, which include the sources that failed and passed full-text screening respectively. From these, it should be possible to reconstruct the full list of sources that passed and failed title and abstract screening.

However, on reviewing the information available in these files, I do not think it will be possible to reliably retrieve the abstracts for a representative sample of these sources. So, this project will be excluded from validation.

# The ‘Eudaimonic Experience’: A Scoping Review of the Concept in Digital Games Research

One file, `2_Eudaimonia rating & second screening of forward chaining searches_final.xlsx`, comes from the project 'The ‘Eudaimonic Experience’: A Scoping Review of the Concept in Digital Games Research' (\url{https://osf.io/q7kdv/}). There is a [preprint scoping review](https://osf.io/c7hny) associated with the project.

## Title and abstract screening results

On review of the files associated with this project, I could not see how to confidently extract title and abstract screening results. This project will therefore be excluded from validation.

# Evaluations of the uptake and impact of the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) Statement and extensions

One file, `PRISMA_title_abstract_screen.xlsx`, comes from the project 'Evaluations of the uptake and impact of the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) Statement and extensions' (\url{https://osf.io/7x2mp/}). There is a [published scoping review](https://systematicreviewsjournal.biomedcentral.com/articles/10.1186/s13643-017-0663-8) associated with the project.

My short name for this review will be `PRISMA`.

## Title and abstract screening results

`PRISMA_title_abstract_screen.xlsx` does contain a clear list of references as well as whether or not they passed title and abstract screening. The question will be whether abstracts can be confidently retrieved from this list of references. I'll start by loading and cleaning the list of sources.

```{r}
PRISMA_sources <- read_excel("osf_files/PRISMA_title_abstract_screen.xlsx") %>%
  rename(source = `Citation`, retrieve = `Retrieve?`)
```

I'll clean up the 'retrieve' column.

```{r}
PRISMA_sources %>%
  distinct(retrieve)

PRISMA_sources <- PRISMA_sources %>%
  mutate(human_includes = retrieve == "Yes") %>%
  select(-retrieve)
```

I'll check there are no sources appearing more than once in the sources list.

```{r}
PRISMA_sources %>%
  count(source) %>%
  filter(n > 1) %>%
  nrow()
```

It turns out that there are 275 replicates. Is the human inclusion decision always replicated between these?

```{r}
PRISMA_sources %>%
  count(source, human_includes) %>%
  filter(n > 1) %>%
  nrow()
```

Not always. I'll de-replicate the sources, and completely remove any source for which there is a conflicting human recommendation.

```{r}
PRISMA_sources <- PRISMA_sources %>%
  group_by(source) %>%
  mutate(conflicting = length(unique(human_includes)) > 1) %>%
  ungroup() %>%
  filter(! conflicting) %>%
  select(-conflicting)

PRISMA_sources <- PRISMA_sources %>%
  distinct(source, human_includes)
```

Now, I'll try to retrieve the abstracts using the easyPubMed package. This function will be memoised.

```{r}
get_metadata_from_pubmed <- function(s) {
  cli_alert_info("Getting metadata from PubMed for:")
  cli_text(s)
  my_pubmed_ids <- get_pubmed_ids(s)
  my_data <- fetch_pubmed_data(my_pubmed_ids, encoding = "ASCII")
  df <- table_articles_byAuth(my_data, included_authors = "first", max_chars = 2000, 
                              encoding = "ASCII") %>% as_tibble()

  if (nrow(df) > 1) {
    cli_alert_warning("Multiple search results retrieved, returning top result only")
    df <- df[1, ]
  }
  return(df)
}
get_metadata_from_pubmed <- slowly(get_metadata_from_pubmed, rate = rate_delay(0.1))
get_metadata_from_pubmed <- memoise(get_metadata_from_pubmed)
```

This process turns out to be prohibitively slow. I will hold this project in reserve but for now will not include it for validation.


# Complementary, Alternative, and Integrative Medicine-Specific COVID-19 Misinformation on Social Media

This project (id ytz5e) has already been used for testing so is not eligible for use for validation.

# Melanoma

A single file `Melanoma Data.xlsx` comes from the project 'Scoping Review – Melanoma' (\url{https://osf.io/knje4/}). There is a protocol published [here](https://osf.io/feg5x) which contains sufficient information on the study objectives, inclusion and exclusion criteria.

My short name for this review will be `melanoma`.

## Title and abstract screening results

`Melanoma Data.xlsx` contains a sheet 'Rayyan 2.0 Inclusions' which seems to summarise the results of title and abstract screening. However, on inspection it appears the 'abstract' column is blank. This is not insurmountable as the PubMed ID appears to be included for almost all sources, which means the abstract can be readily retrieved.

```{r}
melanoma_sources <- read_excel(
  "osf_files/Melanoma Data.xlsx",
  sheet = "Rayyan 2.0 Inclusions",
  range = "A1:D136",
  col_types = c("text", "numeric", "text", "text")
) %>%
  select(title, PMID = `Pubmed ID`, exclude_reason = `Exclude? w/ Reason`) %>%
  mutate(PMID = as.character(PMID))
```

As suspected, none of the abstracts are provided. Can they be retrieved from PubMed?

```{r}
count(melanoma_sources, is.na(PMID))
```

There are 8 missing PubMed IDs. It's unclear whether the authors had access to the abstracts for these sources, but since each source included a URL to either a PubMed or Embase page for the source which normally would display the title and abstract, it is fair to assume they did. I'll try to manually find and splice in the missing values.

```{r}
melanoma_sources %>%
  filter(is.na(PMID)) %>%
  pull(title)

missing_PMIDs <- tribble(
  ~title, ~manual_PMID,
  "Late-Stage Melanoma in New York State: Associations with Socioeconomic Factors and Healthcare Access at the County Level.", "33516743",
  "Quantitative associations between health insurance and stage of melanoma at diagnosis among nonelderly adults in the United States.", "31714593",
  "Rural melanoma patients in Maryland do not present with more advanced disease than urban patients.", "34118809",
  "Socioeconomic status and survival for patients with melanoma in the United States: an NCDB analysis.", "29736922",
  "The impact of demographics, socioeconomics, and health care access on melanoma outcomes.", "32783908",
  "The ongoing racial disparities in melanoma: An analysis of the Surveillance, Epidemiology, and End Results database (1975-2016)", "32861710",
  "The Role of Neighborhood Characteristics in Late Stage Melanoma Diagnosis among Hispanic Men in California, Texas, and Florida, 1996-2012", "28702054",
  "Trends in malignant melanoma mortality in 31 countries from 1985 to 2015.", "32133614"
)

melanoma_sources <- melanoma_sources %>%
  left_join(missing_PMIDs) %>% 
  mutate(PMID = coalesce(PMID, manual_PMID)) %>%
  select(-manual_PMID)
```

I'll now attempt to retrieve the abstracts, using the rentrez package. I'll memoise this function.

```{r}
get_pm_abstract <- function(PMID) {
  entrez_fetch(db = "pubmed", id = PMID, rettype = "xml", parsed = T) %>%
    xpathApply('//PubmedArticle//Article', function(x) xmlValue(xmlChildren(x)$Abstract)) %>%
    unlist()
}
get_pm_abstract <- insistently(get_pm_abstract)
get_pm_abstract <- possibly(get_pm_abstract, otherwise = NA_character_)
get_pm_abstract <- memoise(get_pm_abstract, cache = cachem::cache_disk(dir = "cache"))

melanoma_sources <- melanoma_sources %>%
  mutate(abstract = map_chr(PMID, get_pm_abstract))

melanoma_sources %>%
  filter(is.na(abstract))
```

There are seven sources for which abstract fetching failed, including one with a missing PMID (for some reason this was given as a DOI in the original spreadsheet). Interestingly, there is a close but not perfect overlap with the sources that were missing PMIDs. On manual review, these are all sources with no abstracts (e.g. letters rather than articles). I'll remove them from the dataset.

```{r}
melanoma_sources <- melanoma_sources %>%
  filter(! is.na(abstract))
```

I'll tidy up the decisions and save the sources list to file.

```{r}
melanoma_sources <- melanoma_sources %>%
  mutate(human_includes = is.na(exclude_reason)) %>%
  select(title, abstract, human_includes)

saveRDS(melanoma_sources, "validation_data/melanoma_sources.rds")
```

## Study description

I'll draw the study description and inclusion criteria from the protocol.

```{r}
melanoma_study_description <-
"STUDY DESCRIPTION:

Our study aims to identify the current gaps in literature surrounding dermatologic health inequities with the goal of providing insight for future research to better optimize patient care.

To what degree are health inequities researched within the field of dermatology? The objective of this scoping review is to identify and map the different strengths and gaps in what is known about inequities in the topic of dermatology.

DEFINITIONS:

Health inequities can be defined as broad inequities in healthcare access, quality, and cost related to patient characteristics.

INCLUSION AND EXCLUSION CRITERIA:

The population of this review will include literature of the following study designs: clinical trials, retrospective database reviews, systematic reviews, meta-analysis, scoping reviews, literature reviews, cross-sectional analyses, cohort studies, and case-control studies. Commentaries and correspondences will be excluded, as they do not routinely report original research. To address the concept of the review, only studies pertaining to health inequities within dermatology will be included. To increase feasibility and quality of data extraction, only literature published in the English language will be included. Literature from all countries will be included. Finally, to address the context of this review, we will limit the inequities examined to: race and ethnicity, sex or gender, LGBTQ+ identity, underserved rural populations, education level, income, and occupation status. 

Exclusion criteria will include any study: (1) that was published before 2017 or after 2021, (2) that was written in a language other than English, (3) that was conducted on a topic unrelated to 
dermatology, (4) that failed to analyze one of the health inequities, and (5) that was written as a commentary, correspondence, or letter to the editor.
"
saveRDS(melanoma_study_description, "validation_data/melanoma_study_description.rds")
```

# Vocal production of infants at risk for speech motor involvement

One file, `Interrater Reliability Title Abstract Screening 1.csv`, comes from the project 'Vocal production of infants at risk for speech motor involvement: A scoping review' (\url{https://osf.io/jf3u6/}). There is a [scoping review protocol preprint](https://osf.io/k8tnc) available for the project.

## Title and abstract screening

The file `Interrater Reliability Title Abstract Screening 1.csv` contains only summary data about title and abstract screening, and a review of the other files associated with the project did not find any other useful data. It appears I included this file in error. The project is not suitable for use in validation.

# Social And Psychological Determinants Of Infanticide In Low And Middle-Income Countries

One file, `Search strategy tables-Scoping Review.xlsx`, comes from the project 'Social And Psychological Determinants Of Infanticide In Low And Middle-Income Countries: A Scoping Review' (\url{https://osf.io/9g4f5/}). There does not seem to be any draft, preprint, or final manuscript or protocol associated with the project. As the study description and inclusion/exclusion criteria are not available, the project is thereby not eligible for inclusion 


9g4f5

# Solastalgia

The next file, `Solastalgia re-screening and extraction spreadsheet Dec 2022.xlsx`, relates to the solastalgia review that was used in the testing data so will be excluded.

# Teachers' soft skills

The next two files, `Teachers´ soft skills a Scoping Review - Data extraction.xlsx` and `Teachers´ Soft Skills a SR - Screening NM & OJ(1).xlsx`, relate to the teachers' soft skills review

# Interventions for Organizational Climate

The next file comes from the project 'Interventions for Organizational Climate: Scoping Review' (\url{https://osf.io/2w7ez/}). There is a single file associated with this project, `Vidak et al Excluded List.xlsx`. This only lists sources that were excluded in title and abstract screening. I included this in the hope that on closer analysis of the project there would also be a list of included sources or a list of all considered sources available, but unfortunately it seems this is not the case, so this review will be excluded from validation.

# Data-sharing Policies

The next file comes from the project 'Data-sharing Policies - A Scoping Review' (\url{https://osf.io/pz6vq/}). A protocol for the scoping review is available [here](https://osf.io/bf9pd).

There is one file related to this project, `Bibliographic Data Extraction - Scoping Review (Responses).xlsx`. It has a sheet named 'final data - clean' which seems to summarise the results of source screening as well as act as a data extraction table. However, it is unclear whether the decisions recorded in this table relate to title and abstract screening only or to full text screeing. After looking at the files associated with the project this could still not be clarified, so unfortunately the review was excluded from validation.

# Burden of OA in The Netherlands

The next file comes from the project 'Burden of OA in The Netherlands: a scoping review' (\url{https://osf.io/vgx4n/}). A protocol for the scoping review is available [here](https://osf.io/cgbyw).

There is a single file associated with this review, `Reason exclusion_FT screening_OA in NL.xlsx`. It only contains a list of sources excluded in screening. I had included it in the hope that on closer review of the project files, a full list of sources or list of included sources could be identified, but unfortunately this was not the case. So, unfortunately it will be excluded from validation.

# Medication adherence in chronic diseases

The next file comes from the project 'Medication Adherence in Chronic Diseases: A scoping review' (\url{https://osf.io/b3xe7/}). A preprint of the review was located [here](https://discovery.ucl.ac.uk/id/eprint/10136065/3/Kassianos_Main%20paper_final.pdf).

My short name for this review will be `medication_adherence`.

## Title and abstract screening results

There is one file related to this project: `Screening_after duplicates_final.xlsx`. Sheet 'Sheet1' contains the results of title and abstract screening.

```{r}
medication_adherence_sources <- read_excel("osf_files/Screening_after duplicates_final.xlsx", sheet = "Sheet1") %>%
  select(title = `Article Title`, title_decision = `Title screening`, abstract_decision = `Abstract screening`, URL)
```

It appears title-only screening then title and abstract screening was performed sequentially. So, I'll remove all the sources that failed title-only screening.

```{r}
medication_adherence_sources <- medication_adherence_sources %>%
  filter(str_detect(title_decision, "[Ii]ncluded")) %>%
  select(-title_decision)
```

To retrieve the abstracts, I'll first divide the sources into those with available PubMed IDs and those without.

```{r}
medication_adherence_sources <- medication_adherence_sources %>%
  mutate(PMID = str_extract(URL, "pubmed/\\d+")) %>%
  mutate(PMID = str_remove(PMID, "pubmed/"))

mas_with_pmid <- filter(medication_adherence_sources, ! is.na(PMID))
mas_without_pmid <- filter(medication_adherence_sources, is.na(PMID))
```

For those with PubMed IDs, I'll attempt to retrieve the abstracts with rentrez as above.

```{r}
mas_with_pmid <- mutate(mas_with_pmid, abstract = map_chr(PMID, get_pm_abstract))
```

For those without PubMed IDs, I'll try to retrieve the abstracts from Scopus with the rscopus package. Note that this requires a private Elsevier API key stored in the environmental variable `Elsevier_API`; see \url{https://johnmuschelli.com/rscopus/index.html} for more details.

After working on this for a while, it became clear that there was no reliable way to retrieve the abstracts with the Elsevier API. So, unfortunately this study cannot be used for validation.

# Perception of Major Life Events and Depression

The next file comes from the project 'Perception of Major Life Events and Depression: A Scoping Review' (\url{https://osf.io/dyr8z/}). There is one file associated with this review, `Review_Codingsheet_Results.xlsx`. On closer inspection of this file, it was clear that it could not be determined whether the results represented title and abstract screening or full text screening. So, unfortunately this study was excluded from validation.

# Vocal production of infants at risk for speech motor involvement 

The single file `Interrater Reliability Title Abstract Screening 1.csv` comes from the project "Vocal production of infants at risk for speech motor involvement" (\url{https://osf.io/jf3u6/}). The project includes a review protocol at \url{https://osf.io/k8tnc}.

On review of this file as well as the other files associated with the project, it is clear that the results of title and abstract screening are not available, so unfortunately this project will not be eligible for use in validation.

